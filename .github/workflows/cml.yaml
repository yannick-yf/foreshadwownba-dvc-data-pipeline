name: CML

on:
  push:
    branches:
      - '*'  # Runs on all branches
  schedule:
    - cron: '15 14 * * *'  # Runs every day at 2:15pm UTC
  workflow_dispatch:
jobs:
  data-engineering-pipeline:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install Poetry
        run: pipx install poetry
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11.9"
          cache: "poetry"
      - name: Install dependencies
        run: poetry install --no-root
      - name: Run PyTest
        run: |
            poetry run pytest
      - name: Run Data Feature Engineering Pipeline
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: eu-central-1
        run: |
          poetry run dvc repro post_cleaning_dataset -f
          aws s3 cp ./data/output/nba_games_training_dataset_final.csv s3://foreshadownba/dvc-data-pipeline-output/
          